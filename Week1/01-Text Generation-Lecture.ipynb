{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“˜ Text Generation-Lecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **ì£¼ì˜:** Colab ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ë©´ í™˜ê²½ ë³€ìˆ˜ê°€ ì´ˆê¸°í™”ë˜ë¯€ë¡œ `OPENAI_API_KEY`ë¥¼ ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì§„í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì¤€ë¹„ ë° ë‹¨ì¼ í˜¸ì¶œ ì˜ˆì œ\n",
        "2. GPT-5 ê³„ì—´ ëª¨ë¸ ê°œìš” ë° ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
        "3. ëª¨ë¸ë³„ ì¶œë ¥ ì°¨ì´ ë¹„êµ ì‹¤ìŠµ\n",
        "4. Text Generation ê°œë…ê³¼ instruction/input êµ¬ì¡°\n",
        "5. reasoning.effort Â· text.verbosity Â· max_output_tokens ì œì–´\n",
        "6. ë©€í‹°í„´ ëŒ€í™” êµ¬ì„± ì‹¤ìŠµ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°ëª¨ í¬í•¨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) í™˜ê²½ ì¤€ë¹„ ë° API í‚¤ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip <command> [options]\n",
            "\n",
            "no such option: -U\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### API í‚¤ ì„¤ì • ë° Client ìƒì„±\n",
        "- Colab ë©”ë‰´ `ë³´ì•ˆ ë¹„ë°€(ì—´ì‡  ì•„ì´ì½˜)`ì— `OPENAI_API_KEY`ë¥¼ ì €ì¥í•´ ë‘ì—ˆë‹¤ë©´ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "- ì•„ë˜ì˜ ì½”ë“œì—ì„œ ì˜¤ë¥˜ê°€ ë‚œë‹¤ë©´ API í‚¤ì˜ ì˜¤ë¥˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "except Exception:\n",
        "    print(\"Colab ë©”ë‰´ì˜ ë³´ì•ˆ ë¹„ë°€(ì—´ì‡  ì•„ì´ì½˜)ì—ì„œ í™˜ê²½ ë³€ìˆ˜ê°€ ì œëŒ€ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"âœ… í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OpenAI API ì‹œì‘í•˜ê¸°\n",
        "- Responses APIë¥¼ ì‚¬ìš©í•˜ë©´ ì±—GPTì²˜ëŸ¼ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸(ì½”ë“œ, ìˆ˜ì‹, JSON, ìì—°ì–´ ë“±)ë¥¼ ê°„í¸í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    instructions=\"You are a helpful assistant. Reply in Korean.\",\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ëª¨ë¸ì´ ìƒì„±í•œ ì½˜í…ì¸ ëŠ” response.output ì†ì„±ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, ì•„ë˜ ì˜ˆì‹œëŠ” ì¶œë ¥(response) í˜•íƒœë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "  \"id\": \"resp_07354f378005a78400690d921c77408191b65a4eae80d15ac3\",\n",
        "  \"created_at\": 1762497052.0,\n",
        "  \"error\": null,\n",
        "  \"incomplete_details\": null,\n",
        "  \"instructions\": \"You are a helpful assistant. Reply in Korean.\",\n",
        "  \"metadata\": {},\n",
        "  \"model\": \"gpt-5-nano-2025-08-07\",\n",
        "  \"object\": \"response\",\n",
        "  \"output\": [\n",
        "    {\n",
        "      \"id\": \"rs_07354f378005a78400690d921d59b48191baa7723fcf20871b\",\n",
        "      \"summary\": [],\n",
        "      \"type\": \"reasoning\",\n",
        "      \"content\": null,\n",
        "      \"encrypted_content\": null,\n",
        "      \"status\": null\n",
        "    },\n",
        "    {\n",
        "      \"id\": \"msg_07354f378005a78400690d9223f82081918b05a37be09e6764\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"annotations\": [],\n",
        "          \"text\": \"ë°¤í•˜ëŠ˜ ì•„ë˜ ì‘ì€ ìˆ²ì—ì„œ í•œ ë§ˆë¦¬ì˜ ìœ ë‹ˆì½˜ì´ ë¶€ë“œëŸ¬ìš´ ë¹›ì„ ë‚´ë¿œìœ¼ë©° ì•„ì´ì˜ ê¿ˆìœ¼ë¡œ ê¸¸ì„ ì´ëŒì—ˆê³ , ì•„ì´ëŠ” í¬ê·¼í•œ ì ì— ë“¤ì—ˆë‹¤.\",\n",
        "          \"type\": \"output_text\",\n",
        "          \"logprobs\": []\n",
        "        }\n",
        "      ],\n",
        "      \"role\": \"assistant\",\n",
        "      \"status\": \"completed\",\n",
        "      \"type\": \"message\"\n",
        "    }\n",
        "  ],\n",
        "  \"parallel_tool_calls\": true,\n",
        "  \"temperature\": 1.0,\n",
        "  \"tool_choice\": \"auto\",\n",
        "  \"tools\": [],\n",
        "  \"top_p\": 1.0,\n",
        "  \"background\": false,\n",
        "  \"conversation\": null,\n",
        "  \"max_output_tokens\": null,\n",
        "  \"max_tool_calls\": null,\n",
        "  \"previous_response_id\": null,\n",
        "  \"prompt\": null,\n",
        "  \"prompt_cache_key\": null,\n",
        "  \"reasoning\": {\n",
        "    \"effort\": \"medium\",\n",
        "    \"generate_summary\": null,\n",
        "    \"summary\": null\n",
        "  },\n",
        "  \"safety_identifier\": null,\n",
        "  \"service_tier\": \"default\",\n",
        "  \"status\": \"completed\",\n",
        "  \"text\": {\n",
        "    \"format\": {\n",
        "      \"type\": \"text\"\n",
        "    },\n",
        "    \"verbosity\": \"medium\"\n",
        "  },\n",
        "  \"top_logprobs\": 0,\n",
        "  \"truncation\": \"disabled\",\n",
        "  \"usage\": {\n",
        "    \"input_tokens\": 31,\n",
        "    \"input_tokens_details\": {\n",
        "      \"cached_tokens\": 0\n",
        "    },\n",
        "    \"output_tokens\": 950,\n",
        "    \"output_tokens_details\": {\n",
        "      \"reasoning_tokens\": 896\n",
        "    },\n",
        "    \"total_tokens\": 981\n",
        "  },\n",
        "  \"user\": null,\n",
        "  \"billing\": {\n",
        "    \"payer\": \"developer\"\n",
        "  },\n",
        "  \"prompt_cache_retention\": null,\n",
        "  \"store\": true\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë‚´ê°€ ê·¸ëƒ¥ í•œë²ˆ í•´ë³´ë ¤ê³  ë„£ì€ê±°\n",
        "output = response.output\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ëª¨ë¸ì´ ìƒì„±í•œ ì½˜í…ì¸  ë°°ì—´ì€ `response.output` ì†ì„±ì— ë‹´ê¸°ë©°, ì•„ë˜ì™€ ê°™ì€ í˜•íƒœì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë°°ì—´ì—ëŠ” ë„êµ¬ í˜¸ì¶œ, ì¶”ë¡  ëª¨ë¸ì´ ë§Œë“  reasoning í† í° ë°ì´í„° ë“± ì—¬ëŸ¬ í•­ëª©ì´ í•¨ê»˜ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"output\": [\n",
        "    {\n",
        "      \"id\": \"rs_07354f378005a78400690d921d59b48191baa7723fcf20871b\",\n",
        "      \"summary\": [],\n",
        "      \"type\": \"reasoning\",\n",
        "      \"content\": null,\n",
        "      \"encrypted_content\": null,\n",
        "      \"status\": null\n",
        "    },\n",
        "    {\n",
        "      \"id\": \"msg_07354f378005a78400690d9223f82081918b05a37be09e6764\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"annotations\": [],\n",
        "          \"text\": \"ë°¤í•˜ëŠ˜ ì•„ë˜ ì‘ì€ ìˆ²ì—ì„œ í•œ ë§ˆë¦¬ì˜ ìœ ë‹ˆì½˜ì´ ë¶€ë“œëŸ¬ìš´ ë¹›ì„ ë‚´ë¿œìœ¼ë©° ì•„ì´ì˜ ê¿ˆìœ¼ë¡œ ê¸¸ì„ ì´ëŒì—ˆê³ , ì•„ì´ëŠ” í¬ê·¼í•œ ì ì— ë“¤ì—ˆë‹¤.\",\n",
        "          \"type\": \"output_text\",\n",
        "          \"logprobs\": []\n",
        "        }\n",
        "      ],\n",
        "      \"role\": \"assistant\",\n",
        "      \"status\": \"completed\",\n",
        "      \"type\": \"message\"\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) GPT-5 ëª¨ë¸ ê°œìš” ë° ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
        "\n",
        "### instructions\n",
        "- ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ì— ë„£ëŠ” ì‹œìŠ¤í…œ/ê°œë°œì ì§€ì¹¨ìœ¼ë¡œ, ì‘ë‹µì˜ í†¤Â·ì—­í• Â·ì œì•½ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "- `previous_response_id`ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ì´ì „ í„´ instructionsë¥¼ ëŠê³  ìƒˆ instructionìœ¼ë¡œ ì‰½ê²Œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    - `previous_response_id`: ì´ì „ ì‘ë‹µì˜ ê³ ìœ  IDì…ë‹ˆë‹¤. ì´ ê°’ì„ í™œìš©í•˜ë©´ ë©€í‹°í„´ ëŒ€í™”ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### input\n",
        "- í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, íŒŒì¼ ë“± ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•  ë•Œ ì°¸ê³ í•˜ëŠ” ì…ë ¥ê°’ì…ë‹ˆë‹¤.\n",
        "\n",
        "### model\n",
        "- ì‘ë‹µì„ ìƒì„±í•  ëª¨ë¸ ID(`gpt-5`, `o3` ë“±)ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "- ëª¨ë¸ë³„ ì„±ëŠ¥ê³¼ ë¹„ìš©ì€ [OpenAI ëª¨ë¸ ê°€ì´ë“œ](https://platform.openai.com/docs/models)ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
        "\n",
        "### max_output_tokens\n",
        "- ê°€ì‹œ ì¶œë ¥ í† í°(visible output token)ê³¼ ì¶”ë¡  í† í°(resoning token)ì„ ëª¨ë‘ í¬í•¨í•œ ìµœëŒ€ ìƒì„± ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        instructions=\"You are a helpful assistant. Reply in Korean.\", \n",
        "        input=\"Write a one-sentence bedtime story about a unicorn.\",\n",
        "    )\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "instruction ìˆ˜ì •: í•´ì ì²˜ëŸ¼ ë§í•´ì¤˜.\\\n",
        "instruction ìˆ˜ì •: ì¼ë³¸ì–´ë¡œ ë‹µí•´ì¤˜.\\\n",
        "input ìˆ˜ì •: write a three-sentence bedtime story about a rabbit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_output_tokens ì˜ˆì œ\n",
        "for tokens in [300, 500, 1000]:\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        instructions=\"You are a helpful assistant. Reply in Korean.\",\n",
        "        input=\"Write a one-sentence bedtime story about a unicorn.\",\n",
        "        max_output_tokens=tokens\n",
        "    )\n",
        "    print(f\"\\n--- max_output_tokens={tokens} ---\")\n",
        "    print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT-5 ëª¨ë¸ ë¼ì¸ì—…"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GPT-5 ì‹œë¦¬ì¦ˆëŠ” ì´ ì„¸ ê°€ì§€ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤. ì„ íƒ ì‹œ ì•„ë˜ íŠ¹ì„±ì„ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "\n",
        "- gpt-5: ë³µì¡í•œ ì¶”ë¡ , ê´‘ë²”ìœ„í•œ ìƒì‹, ì½”ë“œ ì‘ì„± ë˜ëŠ” ë‹¤ë‹¨ê³„ ì‘ì—… ë“± ê°€ì¥ ì–´ë ¤ìš´ ë¬¸ì œì— ì í•©\n",
        "- gpt-5-mini: í•©ë¦¬ì ì¸ ë¹„ìš©ì— ê· í˜• ì¡íŒ ì„±ëŠ¥ê³¼ ì†ë„ë¥¼ ì œê³µí•˜ë©°, ì±„íŒ…ì´ë‚˜ ì¼ë°˜ì  ê³¼ì œì— ì¶”ì²œ\n",
        "- gpt-5-nano: ì•„ì£¼ ë¹ ë¥¸ ì²˜ë¦¬ì™€ ì €ë ´í•œ ë¹„ìš©ì´ ì¥ì ì´ë©°, ë‹¨ìˆœ ë¶„ë¥˜Â·ì§€ì‹œ ìˆ˜í–‰ ë“± ëŒ€ëŸ‰ ì²˜ë¦¬ ìš©ë„ì— ì í•©\n",
        "\n",
        "ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì´ ì‘ì•„ì§ˆìˆ˜ë¡ ë¹„ìš©ê³¼ ëŒ€ê¸°ì‹œê°„ì€ ë‚®ì•„ì§€ì§€ë§Œ, ë²”ìš© ìƒì‹ì´ë‚˜ ì°½ì˜ì„±ì´ ë‹¤ì†Œ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì˜ ì •ì˜ëœ ê³¼ì œì—ì„œëŠ” ì‘ì€ ëª¨ë¸ì´ ì˜¤íˆë ¤ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "> **ì²´í¬í¬ì¸íŠ¸**: ê°•ì˜ ì „ ìµœì‹  ëª¨ë¸ ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ë¥¼ í™•ì¸í•˜ê³  í…Œì´ë¸”ì„ ê°±ì‹ í•˜ì„¸ìš”.\n",
        "> **ì£¼ì˜**: GPT-5 ê³„ì—´ì€ `temperature`, `top_p`, `logprobs` íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  `reasoning.effort`, `text.verbosity`, `max_output_tokens`ë¡œ ì œì–´í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) ëª¨ë¸ë³„ ì¶œë ¥ ì°¨ì´ ë¹„êµ ì‹¤ìŠµ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Text Generation ê°œë…ê³¼ instruction/input êµ¬ì¡°\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_prompt = \"ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.\"\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-5-nano\", # gpt-5, gpt-5-mini, gpt-5-nano\n",
        "    instructions=\"You are a helpful instructor. Reply in Korean and keep the answer well-structured.\",\n",
        "    input=llm_prompt,\n",
        ")\n",
        "print(resp.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "âœ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ íë¦„ ì •ë¦¬\n",
        " \n",
        "GPT-5 APIì—ì„œ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µì„ ë°›ì„ ë•Œ ë„ì°©í•˜ëŠ” ì´ë²¤íŠ¸ì™€ ì²˜ë¦¬ ìˆœì„œ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
        "| ë‹¨ê³„ | event.type                    | ì„¤ëª…                             | ì˜ˆì‹œ ì¶œë ¥                        |\n",
        "|------|-------------------------------|----------------------------------|----------------------------------|\n",
        "| 1    | response.output_text.delta    | ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ ì¼ë¶€ ë„ì°©    | \"ëŒ€í˜•\", \" ì–¸ì–´\", \" ëª¨ë¸ì€\" ...   |\n",
        "| 2    | response.refusal.delta        | (ì„ íƒì ) ëª¨ë¸ì´ ê±°ì ˆ ë©”ì‹œì§€ ì „ì†¡  | \"ì£„ì†¡í•©ë‹ˆë‹¤, í•´ë‹¹ ìš”ì²­ì€...\"     |\n",
        "| 3    | response.error                | ì˜¤ë¥˜ ë°œìƒ                        | \"Rate limit exceeded\"            |\n",
        "| 4    | response.completed            | ëª¨ë“  í† í° ìƒì„± ì¢…ë£Œ ì•Œë¦¼          | \"Completed\"                      |\n",
        "| 5    | stream.get_final_response()   | ì „ì²´ ì‘ë‹µ ê²°ê³¼(ìµœì¢… í…ìŠ¤íŠ¸ ë“±)    | (ìµœì¢… ìƒì„± ë¬¸ì¥ ì „ì²´ ë°˜í™˜)       |\n",
        "- ë³´í†µ ë‹¨ê³„ 1ì—ì„œ ì—¬ëŸ¬ ë²ˆ eventê°€ ë“¤ì–´ì˜¤ë©°, ê° í† í°ì´ë‚˜ ì¡°ê°ë§ˆë‹¤ ë„ì°©í•©ë‹ˆë‹¤.\n",
        "- ë‹¨ê³„ 5ëŠ” ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ í›„ í•œ ë²ˆë§Œ í˜¸ì¶œí•˜ì—¬, í†µí•© ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- ê±°ì ˆ(event.type = response.refusal.delta) ë˜ëŠ” ì˜¤ë¥˜(event.type = response.error) ë°œìƒ ì‹œì—ëŠ” ì´í›„ ìƒì„±ì´ ì¤‘ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- ì‹¤ ì„œë¹„ìŠ¤ì—ì„œëŠ” ê° event.typeì— ë”°ë¼ ì¶œë ¥ ì²˜ë¦¬, ì˜ˆì™¸ì²˜ë¦¬ë¥¼ ë¶„ê¸°í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ì´ê±´ ì¢€ í•˜ë©´ì„œ, ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦¬ë‹ˆ, stream ê¸°ëŠ¥ì„ í•œë²ˆ í•´ë³´ê² ë‹¤ëŠ” ì‹ìœ¼ë¡œ ì „ê°œí•˜ë©´ ì¢‹ê² ë‹¤.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m llm_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-5-nano\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# gpt-5, gpt-5-mini, gpt-5-nano\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful instructor. Reply in Korean and keep the answer well-structured.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mllm_prompt,\n\u001b[0;32m      7\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m resp:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(event)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "# ì´ê±´ ì¢€ í•˜ë©´ì„œ, ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦¬ë‹ˆ, stream ê¸°ëŠ¥ì„ í•œë²ˆ í•´ë³´ê² ë‹¤ëŠ” ì‹ìœ¼ë¡œ ì „ê°œí•˜ë©´ ì¢‹ê² ë‹¤.\n",
        "llm_prompt = \"ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.\"\n",
        "resp = client.responses.create(\n",
        "    model=\"gpt-5-nano\", # gpt-5, gpt-5-mini, gpt-5-nano\n",
        "    instructions=\"You are a helpful instructor. Reply in Korean and keep the answer well-structured.\",\n",
        "    input=llm_prompt,\n",
        "    stream = True,\n",
        ")\n",
        "\n",
        "for event in resp:\n",
        "    print(event)\n",
        "\n",
        "# ìœ„ì™€ ê°™ì´ í•˜ë©´ ì•ˆë˜ê³ ..\n",
        "\n",
        "for event in resp:\n",
        "    if event.type == \"response.output_text.delta\":\n",
        "        print(event.delta, end=\"\")\n",
        "        \n",
        "\n",
        "#print(resp.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) reasoning.effort Â· text.verbosity Â· max_output_tokens ì œì–´\n",
        "\n",
        "### reasoning.effort íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ì „ ì–¼ë§ˆë‚˜ ë§ì€ ì¶”ë¡  í† í°ì„ ì‚¬ìš©í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
        "- reasoning effortëŠ” minimal, low, medium, highë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "   - minimal: ë¹ ë¥´ê³ , ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ ë‹µë³€\n",
        "   - low: ë¹ ë¥¸ ì†ë„, í† í° ì ê²Œ ì‚¬ìš©\n",
        "   - medium: ì†ë„-ì •í™•ì„± ê· í˜•, GPT-5ì˜ ê¸°ë³¸ê°’\n",
        "   - high: ê¼¼ê¼¼í•˜ê³ , ê¹Šì´ ìˆëŠ” ì„¤ëª… ì œê³µ\n",
        "- minimalì€ íŠ¹íˆ ì½”ë“œ ì‘ì„±ì´ë‚˜ ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ìƒí™©ì—ì„œ ë¹ ë¥´ê²Œ ì‘ë‹µí•˜ë©´ì„œë„ ì£¼ì–´ì§„ ì§€ì¹¨ì„ ì˜ ì§€í‚¤ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=\"ë‚¨ì‚°íƒ€ì›Œ ì™¸ë²½ì„ 1mm ë‘ê»˜ì˜ ê¸ˆìœ¼ë¡œ ë„ê¸ˆí•˜ë ¤ë©´ ê¸ˆì´ ëª‡ kgì´ë‚˜ í•„ìš”í• ê¹Œìš”?\",\n",
        "    reasoning={\n",
        "        \"effort\": \"minimal\" # low, medium, high\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### text.verbosity íŒŒë¼ë¯¸í„°ëŠ” ì¶œë ¥ ë‹µë³€ì˜ ê¸¸ì´(í† í° ìˆ˜)ì— ì˜í–¥ì„ ì£¼ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.\n",
        "- verbosityëŠ” low, medium, high ì˜µì…˜ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "   - low: ì§§ê³ , ê°„ê²°í•˜ë©° ìš”ì ë§Œ ì „ë‹¬ (ì˜ˆ: ìš”ì•½, ì½”ë“œ ìŠ¤ë‹ˆí«)\n",
        "   - medium: ì ì ˆí•œ ìƒì„¸ ì„¤ëª…ê³¼ ê¸¸ì´, GPT-5ì˜ ê¸°ë³¸ê°’\n",
        "   - high: ê¸¸ê³ , ìì„¸í•˜ë©° ì„¸ë¶€ ì„¤ëª…ì´ ë§ì€ ë‹µë³€ ì œê³µ\n",
        "- ì‘ìš© ëª©ì ì— ë”°ë¼ ìƒì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ë©´ high, ì•„ì£¼ ì§§ì€ ê²°ê³¼ê°€ ìš”êµ¬ë˜ë©´ lowë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- ì‹¤ì œ ë‹µë³€ ê¸¸ì´ëŠ” í”„ë¡¬í”„íŠ¸, max_output_tokens ë“± ë‹¤ë¥¸ ì„¤ì •ì—ë„ ì˜í–¥ë°›ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=\"ì‚¶, ìš°ì£¼ ê·¸ë¦¬ê³  ëª¨ë“  ê²ƒì— ëŒ€í•œ ê¶ê·¹ì ì¸ ì§ˆë¬¸ì˜ ë‹µì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "    text={\n",
        "        \"verbosity\": \"low\" # medium, high\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ì‹¤ìŠµ ì§€ì‹œ: ì›í•˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°í•©ë§Œ ë‚¨ê¸°ê³  ì‹¶ë‹¤ë©´ ë£¨í”„ë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì„ íƒì ìœ¼ë¡œ ì‹¤í–‰í•˜ë„ë¡ ìˆ˜ì •í•´ ë³´ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ë©”ì‹œì§€ ì—­í• (role)ê³¼ instructions íŒŒë¼ë¯¸í„°\n",
        "| ì—­í• (role)     | ì„¤ëª…                                                    | ìš°ì„ ìˆœìœ„                                 |\n",
        "| -------------- | ------------------------------------------------------- | ---------------------------------------- |\n",
        "| developer      | ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œìê°€ ì œê³µí•˜ëŠ” instructions             | ê°€ì¥ ë†’ìŒ (user ë©”ì‹œì§€ë³´ë‹¤ ìš°ì„ )         |\n",
        "| user           | ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” instructions                        | developer ë©”ì‹œì§€ë³´ë‹¤ ë‚®ê³  assistantë³´ë‹¤ ë†’ìŒ |\n",
        "| assistant      | ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ì‘ë‹µ ë©”ì‹œì§€                              | ê°€ì¥ ë‚®ìŒ                                |\n",
        "\n",
        "- `instructions` íŒŒë¼ë¯¸í„°ì™€ ë©”ì‹œì§€ ì—­í• ì„ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ê¶Œí•œ ìˆ˜ì¤€ì´ ë‹¤ë¥¸ ì§€ì‹œë¥¼ ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- `instructions`ëŠ” í†¤, ëª©í‘œ, ì˜¬ë°”ë¥¸ ì‘ë‹µ ì˜ˆì‹œ ë“± ê³ ìˆ˜ì¤€ í–‰ë™ ì§€ì¹¨ì„ ì •ì˜í•˜ë©° `input` íŒŒë¼ë¯¸í„°ë³´ë‹¤ ë†’ì€ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
        "- OpenAI ëª¨ë¸ ìŠ¤í™ì—ì„œëŠ” ì—­í•  ìš°ì„ ìˆœìœ„ë¥¼ `developer` > `user` > `assistant` ìˆœìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### instructions íŒŒë¼ë¯¸í„°ë¡œ í…ìŠ¤íŠ¸ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    instructions=\"í•´ì ì²˜ëŸ¼ ë§í•´ ì£¼ì„¸ìš”.\",\n",
        "    input=\"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ë¶€ì‚°ì¸ê°€ìš”?\",\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `instructions` íŒŒë¼ë¯¸í„°ëŠ” ì‘ë‹µ ìƒì„± ì‹œ ìš°ì„  ì ìš©ë˜ëŠ” ì „ì—­ ì§€ì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ë©”ì‹œì§€ ì—­í• ì„ ì‚¬ìš©í•œ ë™ì¼ ì˜ˆì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"í•´ì ì²˜ëŸ¼ ë§í•´ ì£¼ì„¸ìš”.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ë¶€ì‚°ì¸ê°€ìš”?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ì—­í•  ê¸°ë°˜ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ë©´ `developer` ì§€ì‹œê°€ `user` ìš”ì²­ë³´ë‹¤ ìš°ì„  ì ìš©ë˜ë©°, ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ë‹µë³€ì€ `assistant` ì—­í• ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.\n",
        "- í”„ë¡œê·¸ë˜ë°ì— ë¹„ìœ í•˜ë©´ `developer` ë©”ì‹œì§€ëŠ” í•¨ìˆ˜ ì •ì˜ì²˜ëŸ¼ ì‹œìŠ¤í…œ ê·œì¹™ê³¼ ë¡œì§ì„ ì œê³µí•˜ê³ , `user` ë©”ì‹œì§€ëŠ” ê·¸ í•¨ìˆ˜ì— ì „ë‹¬í•˜ëŠ” ì¸ìì™€ ê°™ìœ¼ë©°, ëª¨ë¸ì´ ìƒì„±í•œ `assistant` ë©”ì‹œì§€ëŠ” ê²°ê³¼ì— í•´ë‹¹í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) ë©€í‹°í„´ ëŒ€í™” êµ¬ì„± ì‹¤ìŠµ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°ëª¨ í¬í•¨)\n",
        "\n",
        "### ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê¸°ë³¸ ê°œë…\n",
        "- Responses APIëŠ” ìë™ìœ¼ë¡œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë³´ì¡´í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì§ì ‘ ë©”ì‹œì§€ë¥¼ ëˆ„ì í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "- ê° í„´ë§ˆë‹¤ `role`ê³¼ `content`ê°€ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ì¶”ê°€í•˜ê³ , ëª¨ë¸ì´ ìƒì„±í•œ ì‘ë‹µë„ íˆìŠ¤í† ë¦¬ì— í¬í•¨í•´ì•¼ ë‹¤ìŒ ìš”ì²­ì—ì„œ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- `previous_response_id`ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ì „ ì‘ë‹µì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê°„ë‹¨íˆ ì¬ì‚¬ìš©í•´ ì²´ì¸ ë˜ëŠ” ë¶„ê¸°í˜• ê¸°ë¡ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    instructions=\"You are a helpful assistant. You must answer in Korean.\",\n",
        "    input=\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask(question):\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        instructions=\"You are a helpful assistant. You must answer in Korean.\",\n",
        "        input=question,\n",
        "    )\n",
        "    return response.output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì²« ë²ˆì§¸ ì§ˆë¬¸\n",
        "ask(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë‘ ë²ˆì§¸ ì§ˆë¬¸\n",
        "ask(\"ì˜ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ìœ„ì˜ ì˜ˆì‹œì²˜ëŸ¼ Responses APIë¥¼ ë§¤ë²ˆ ë‹¨ì¼ í˜¸ì¶œë¡œë§Œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ **ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•´ ì—‰ëš±í•œ ë‹µë³€**ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "í•´ê²° ë°©ë²•ì€ ê°„ë‹¨í•©ë‹ˆë‹¤. ê° í„´ì˜ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ëª¨ë¸ ì‘ë‹µì„ ìˆœì„œëŒ€ë¡œ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•´ ë‹¤ìŒ ìš”ì²­ì˜ `input`ìœ¼ë¡œ ì „ë‹¬í•˜ë©´, ì±—ë´‡ì´ ì´ì „ ë¬¸ë§¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context = [\n",
        "    {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": \"You are a helpful assistant. You must answer in Korean.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "res1 = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=context,\n",
        ")\n",
        "\n",
        "first_answer = res1.output_text\n",
        "print(\"ì²« ë²ˆì§¸ ì‘ë‹µ:\", first_answer)\n",
        "\n",
        "context.append({\"role\": \"assistant\", \"content\": first_answer})\n",
        "context.append({\"role\": \"user\", \"content\": \"ë°©ê¸ˆ ë‹µë³€ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”.\"})\n",
        "\n",
        "res2 = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=context,\n",
        ")\n",
        "\n",
        "print(\"\\në‘ ë²ˆì§¸ ì‘ë‹µ:\", res2.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ì´ì œ Responses API í˜¸ì¶œì„ í•¨ìˆ˜ë¡œ ê°ì‹¸ì„œ íˆìŠ¤í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask(question, message_history=None, *, model=\"gpt-5-mini\", effort=\"medium\"):\n",
        "    if message_history is None:\n",
        "        message_history = [\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": \"You are a helpful assistant. You must answer in Korean.\",\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    message_history.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=model,\n",
        "        input=message_history,\n",
        "        reasoning={\"effort\": effort},\n",
        "    )\n",
        "\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": response.output_text})\n",
        "    return message_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì´ˆ ì§ˆë¬¸\n",
        "message_history = ask(\"ì–‘ìì—­í•™ì— ëŒ€í•´ì„œ ì‰½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”\")\n",
        "# ìµœì´ˆ ë‹µë³€\n",
        "print(message_history[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "message_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë‘ ë²ˆì§¸ ì§ˆë¬¸\n",
        "message_history = ask(\n",
        "    \"ì´ì „ì˜ ë‚´ìš©ì„ ì˜ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”\", message_history=message_history\n",
        ")\n",
        "# ë‘ ë²ˆì§¸ ë‹µë³€\n",
        "print(message_history[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### previous_response_idë¥¼ í™œìš©í•œ Responses API ë©€í‹°í„´ ëŒ€í™” ì˜ˆì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context = [\n",
        "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant. You must answer in Korean.\"},\n",
        "    {\"role\": \"user\", \"content\": \"ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"},\n",
        "]\n",
        "\n",
        "res1 = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=context,\n",
        ")\n",
        "\n",
        "# ì´ì „ ì‘ë‹µì˜ response_idë¥¼ í™œìš©í•˜ì—¬ ëŒ€í™” ì´ì–´ê°€ê¸°\n",
        "res2 = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    input=[{\"role\": \"user\", \"content\": \"ê·¸ ë„ì‹œì˜ ì¸êµ¬ë„ ì•Œë ¤ ì£¼ì„¸ìš”.\"}],\n",
        "    previous_response_id=res1.id,\n",
        ")\n",
        "\n",
        "print(res2.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì°¸ê³  ìë£Œ\n",
        "- https://platform.openai.com/docs\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm_api",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
