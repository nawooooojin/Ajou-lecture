{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa26bd4",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“˜ Week 1 â€” Chat â†’ **Responses API** ì‹¤ìŠµ (Colab)\n",
    "## `ChatCompletion`ì—ì„œ **Responses API**ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ (ëª¨ë¸: **gpt-5-mini**)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ê¸°ì¡´ `ChatCompletion` ìŠ¤íƒ€ì¼ì„ **Responses API** ê¶Œì¥ í˜•ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.  \n",
    "í•µì‹¬ ë³€ê²½: **`instructions` + `input` ë¶„ë¦¬**, **GPT-5 ì „ìš© íŒŒë¼ë¯¸í„°**(`reasoning.effort`, `text.verbosity`, `max_output_tokens`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9d8ea",
   "metadata": {},
   "source": [
    "\n",
    "## 1) í™˜ê²½ ì…‹ì—…\n",
    "ìµœì‹  OpenAI Python SDK ì„¤ì¹˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -qU install openai>=1.55.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0a597",
   "metadata": {},
   "source": [
    "\n",
    "## 2) API í‚¤ ì„¤ì •\n",
    "Colab ìƒë‹¨ **Settings â†’ Variables**ì— `OPENAI_API_KEY`ë¥¼ ì €ì¥í–ˆë‹¤ë©´ ìë™ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "ì—†ìœ¼ë©´ ì•„ë˜ ì…€ì—ì„œ ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = None\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "print(\"âœ… API key set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ab06c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” & ëª¨ë¸ ì„ íƒ (í´ë°±)\n",
    "- ê¸°ë³¸: **`gpt-5-mini`**\n",
    "- ì ‘ê·¼ ë¶ˆê°€ ì‹œ: **`gpt-4o-mini`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac95d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "PRIMARY_MODEL = \"gpt-5-mini\"\n",
    "FALLBACK_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def pick_model():\n",
    "    try:\n",
    "        _ = client.responses.create(\n",
    "            model=PRIMARY_MODEL,\n",
    "            reasoning={\"effort\": \"minimal\"},\n",
    "            text={\"verbosity\": \"low\"},\n",
    "            input=\"ping\",\n",
    "            max_output_tokens=5,\n",
    "        )\n",
    "        return PRIMARY_MODEL\n",
    "    except Exception as e:\n",
    "        print(\"[warn] gpt-5-mini not available â†’ falling back to gpt-4o-mini\")\n",
    "        return FALLBACK_MODEL\n",
    "\n",
    "MODEL = pick_model()\n",
    "print(\"Using model:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1e653",
   "metadata": {},
   "source": [
    "\n",
    "## 4) ë§ˆì´ê·¸ë ˆì´ì…˜ Quickstart\n",
    "`ChatCompletion`ì˜ `messages=[...]` ëŒ€ì‹ , **Responses API**ì—ì„œëŠ” **`instructions`(ì—­í• /ìŠ¤íƒ€ì¼)** + **`input`(ì§ˆë¬¸)**ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc4ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"medium\"},\n",
    "    instructions=\"You are a helpful assistant that explains concepts simply.\",\n",
    "    input=\"Explain how transformers work in one paragraph.\",\n",
    "    max_output_tokens=180,\n",
    ")\n",
    "print(response.output_text)\n",
    "try:\n",
    "    print(\"\\n[usage]\", response.usage)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7729a9",
   "metadata": {},
   "source": [
    "\n",
    "### ğŸ´â€â˜ ï¸ ìŠ¤íƒ€ì¼ ì§€ì‹œ (pirate tone) â€” `instructions` ì˜ˆì‹œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    instructions=\"Talk like a pirate.\",\n",
    "    input=\"Are semicolons optional in JavaScript? Answer briefly.\",\n",
    "    max_output_tokens=60,\n",
    ")\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611729ed",
   "metadata": {},
   "source": [
    "\n",
    "## 5) í—¬í¼ í•¨ìˆ˜ â€” `ask_responses()`\n",
    "`instructions`/`input` êµ¬ì¡°ë¡œ ë¹ ë¥´ê²Œ ì‹¤í—˜í•˜ë„ë¡ ë•ëŠ” ë˜í¼ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_responses(\n",
    "    user_input: str,\n",
    "    instructions: str = \"You are a helpful assistant.\",\n",
    "    reasoning_effort: str = \"medium\",\n",
    "    verbosity: str = \"medium\",\n",
    "    max_tokens: int = 300,\n",
    "    model: str = MODEL,\n",
    "):\n",
    "    r = client.responses.create(\n",
    "        model=model,\n",
    "        reasoning={\"effort\": reasoning_effort},\n",
    "        text={\"verbosity\": verbosity},\n",
    "        instructions=instructions,\n",
    "        input=user_input,\n",
    "        max_output_tokens=max_tokens,\n",
    "    )\n",
    "    return r\n",
    "\n",
    "demo = ask_responses(\"List three tips for writing better prompts.\", verbosity=\"low\", max_tokens=120)\n",
    "print(demo.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd229a2b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) ì‹¤ìŠµ 1 â€” `reasoning.effort` ë¹„êµ\n",
    "ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´ `minimal / low / medium / high` ì‘ë‹µ ì°¨ì´ë¥¼ ê´€ì°°í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Explain overfitting to a beginner in <= 4 sentences.\"\n",
    "for effort in [\"minimal\", \"low\", \"medium\", \"high\"]:\n",
    "    print(f\"\\n=== reasoning.effort = {effort} ===\")\n",
    "    r = ask_responses(question, reasoning_effort=effort, verbosity=\"medium\", max_tokens=220)\n",
    "    print(r.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35877113",
   "metadata": {},
   "source": [
    "\n",
    "## 7) ì‹¤ìŠµ 2 â€” `text.verbosity` ë¹„êµ\n",
    "`low / medium / high`ì— ë”°ë¼ ì‘ë‹µ ê¸¸ì´/ì„¤ëª… ì •ë„ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ ë¹„êµí•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fab1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"What is a binary search tree? Include a tiny Python snippet.\"\n",
    "for v in [\"low\", \"medium\", \"high\"]:\n",
    "    print(f\"\\n=== text.verbosity = {v} ===\")\n",
    "    r = ask_responses(question, reasoning_effort=\"low\", verbosity=v, max_tokens=420)\n",
    "    print(r.output_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf437c38",
   "metadata": {},
   "source": [
    "\n",
    "## 8) ì‹¤ìŠµ 3 â€” `max_output_tokens` ì˜í–¥\n",
    "ì¶œë ¥ ê¸¸ì´ë¥¼ 60 / 150 / 400ìœ¼ë¡œ ë°”ê¿” ë³´ê³ , ì–´ë””ì„œ ì˜ë¦¬ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Give a step-by-step guide to implement a simple REST API server in Python using FastAPI.\"\n",
    "for m in [60, 150, 400]:\n",
    "    print(f\"\\n=== max_output_tokens = {m} ===\")\n",
    "    r = ask_responses(question, reasoning_effort=\"medium\", verbosity=\"high\", max_tokens=m)\n",
    "    print(r.output_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648d86e",
   "metadata": {},
   "source": [
    "\n",
    "## 9) êµ¬ì¡°í™”(JSON) ì‘ë‹µ\n",
    "`response_format={\"type\":\"json_object\"}`ë¡œ íŒŒì‹± ê°€ëŠ¥í•œ ì¶œë ¥ ë°›ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "prompt = \"Summarize in <=2 sentences and extract 3 keywords: GPT-5-mini balances speed, cost, and capability.\"\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    instructions=\"Return a valid JSON object only. Keys: summary, keywords (list).\",\n",
    "    input=prompt,\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=150,\n",
    ")\n",
    "print(\"Raw:\", resp.output_text)\n",
    "try:\n",
    "    print(\"Parsed:\", json.loads(resp.output_text))\n",
    "except Exception as e:\n",
    "    print(\"JSON parse error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87611d5d",
   "metadata": {},
   "source": [
    "\n",
    "## 10) (ì„ íƒ) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "í† í° ë‹¨ìœ„ë¡œ ì ì§„ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e387f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def response_stream(**kwargs):\n",
    "    s = client.responses.stream(**kwargs)\n",
    "    try:\n",
    "        yield s\n",
    "    finally:\n",
    "        s.close()\n",
    "\n",
    "with response_stream(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    instructions=\"Be concise.\",\n",
    "    input=\"Write a 5-line poem about on-device acceleration.\",\n",
    "    max_output_tokens=120,\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == \"response.completed\":\n",
    "            print(\"\\n\\n[completed]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2ac1a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… / ìœ ì˜ì‚¬í•­\n",
    "- **GPT-5 ê³„ì—´ ë¯¸ì§€ì›:** `temperature`, `top_p`, `logprobs` â†’ **ì‚¬ìš© ê¸ˆì§€**\n",
    "- **ì§€ì—° ë‹¨ì¶•:** `reasoning.effort` ë‚®ì¶”ê¸°, `text.verbosity=\"low\"`, `max_output_tokens` ì¶•ì†Œ\n",
    "- **ê³¼ê¸ˆ ê´€ë¦¬:** ê³¼ë„í•œ ì¶œë ¥/ë°˜ë³µ í˜¸ì¶œ ì§€ì–‘, ì¶œë ¥ ê¸¸ì´ ì œí•œ\n",
    "- **ì ‘ê·¼ ê¶Œí•œ:** ì‹¤íŒ¨ ì‹œ ìë™ í´ë°±(`gpt-4o-mini`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0f76a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "_Last updated: 2025-11-06 14:45:48_  \n",
    "Â© Ajou Univ. **ëª¨ë°”ì¼ ì»´í“¨íŒ… íŠ¹ë¡ ** â€” Chat â†’ Responses Migration Lab (gpt-5-mini)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
