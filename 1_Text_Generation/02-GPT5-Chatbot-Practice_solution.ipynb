{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“˜ Week1: GPT-5 ì±—ë´‡ ì‹¤ìŠµ (Solution)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) í™˜ê²½ ì¤€ë¹„ ë° ë‹¨ìˆœ ì¶œë ¥\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openai ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "except Exception:\n",
        "    print(\"Colab ë©”ë‰´ì˜ ë³´ì•ˆ ë¹„ë°€(ì—´ì‡  ì•„ì´ì½˜)ì—ì„œ í™˜ê²½ ë³€ìˆ˜ê°€ ì œëŒ€ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"âœ… í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI API Quick Start ì •ë‹µ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_greeting(client, model, instructions, user_prompt):\n",
        "    \"\"\"Responses API í•œ í„´ í˜¸ì¶œ ì†”ë£¨ì…˜ êµ¬í˜„.\"\"\"\n",
        "    response = client.responses.create(\n",
        "        model=model,\n",
        "        instructions=instructions,\n",
        "        input=user_prompt,\n",
        "    )\n",
        "    return response.output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "greeting = create_greeting(\n",
        "    client=client,\n",
        "    model=\"gpt-5-nano\",\n",
        "    instructions=\"You are a helpful assistant. Reply in Korean.\",\n",
        "    user_prompt=\"ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ê¸°ë¶„ ì¢‹ê²Œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ì¸ì‚¬ë§ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\",\n",
        ")\n",
        "print(greeting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) ë©€í‹°í„´ ëŒ€í™” êµ¬ì„± ì •ë‹µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def request_chat_completion(\n",
        "    client,\n",
        "    model,\n",
        "    history,\n",
        "    *,\n",
        "    reasoning_effort=\"medium\",\n",
        "    verbosity=\"medium\"\n",
        "):\n",
        "    \"\"\"Responses API ë©€í‹°í„´ ëŒ€í™” ì†”ë£¨ì…˜ êµ¬í˜„.\"\"\"\n",
        "    history_payload = [msg.copy() for msg in history]\n",
        "\n",
        "    kwargs = {}\n",
        "    if reasoning_effort:\n",
        "        kwargs[\"reasoning\"] = {\"effort\": reasoning_effort}\n",
        "    if verbosity:\n",
        "        kwargs[\"text\"] = {\"verbosity\": verbosity}\n",
        "\n",
        "    # API í˜¸ì¶œ\n",
        "    response = client.responses.create(\n",
        "        model=model,\n",
        "        input=history_payload,\n",
        "        **kwargs,\n",
        "    )\n",
        "    return response.output_text, response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": \"You are a helpful assistant. Reply in Korean and keep answers concise.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"ë°©ê¸ˆ ì½ì€ ì±…ì„ í•œ ì¤„ë¡œ ìš”ì•½í•´ ë‹¬ë¼ê³  ë¶€íƒí•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ ì¤˜.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "first_text, first_response = request_chat_completion(\n",
        "    client=client,\n",
        "    model=\"gpt-5-mini\",\n",
        "    history=conversation,\n",
        "    reasoning_effort=\"medium\",\n",
        ")\n",
        "print(\"ì²« ë²ˆì§¸ ì‘ë‹µ:\", first_text)\n",
        "\n",
        "conversation.append({\"role\": \"assistant\", \"content\": first_text})\n",
        "conversation.append({\"role\": \"user\", \"content\": \"ì´ ë‚´ìš©ì„ ë” ì¹œê·¼í•˜ê²Œ ë°”ê¿” ì¤„ë˜?\"})\n",
        "\n",
        "second_text, second_response = request_chat_completion(\n",
        "    client=client,\n",
        "    model=\"gpt-5-mini\",\n",
        "    history=conversation,\n",
        ")\n",
        "print(\"\\në‘ ë²ˆì§¸ ì‘ë‹µ:\", second_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) ì±—ë´‡ ë§Œë“¤ê¸° ì‹¤ìŠµ ì •ë‹µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ChatSession:\n",
        "    \"\"\"Responses API ê¸°ë°˜ ë©€í‹°í„´ ì±—ë´‡ ì„¸ì…˜ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° (ì •ë‹µ).\"\"\"\n",
        "\n",
        "    client: OpenAI\n",
        "    model: str = \"gpt-5-mini\"\n",
        "    developer_message: str = (\n",
        "        \"You are a helpful assistant. You must answer in Korean and keep answers clear.\"\n",
        "    )\n",
        "    reasoning_effort: str = \"medium\"\n",
        "    verbosity: str = \"medium\"\n",
        "    history: list = field(default_factory=list)\n",
        "    last_response_id: object = field(default=None, init=False)\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸° developer ë©”ì‹œì§€ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤.\"\"\"\n",
        "        self.history = [\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": self.developer_message,\n",
        "            }\n",
        "        ]\n",
        "        self.last_response_id = None\n",
        "\n",
        "    def send(self, user_message: str):\n",
        "        \"\"\"ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ì™€ response ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "        cleaned = user_message.strip()\n",
        "        if not cleaned:\n",
        "            raise ValueError(\"user_messageëŠ” ë¹„ì–´ ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        self.history.append({\"role\": \"user\", \"content\": cleaned})\n",
        "\n",
        "        message_text, response = request_chat_completion(\n",
        "            client=self.client,\n",
        "            model=self.model,\n",
        "            history=self.history,\n",
        "            reasoning_effort=self.reasoning_effort,\n",
        "        )\n",
        "\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": message_text})\n",
        "        self.last_response_id = response.id\n",
        "        return message_text, response\n",
        "\n",
        "    def pretty_history(self):\n",
        "        \"\"\"í˜„ì¬ íˆìŠ¤í† ë¦¬ë¥¼ ì½ê¸° ì‰¬ìš´ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "        lines = []\n",
        "        for msg in self.history:\n",
        "            prefix = \"ì‚¬ìš©ì\" if msg[\"role\"] == \"user\" else \"assistant\" if msg[\"role\"] == \"assistant\" else msg[\"role\"]\n",
        "            lines.append(f\"[{prefix}] {msg['content']}\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chatbot = ChatSession(\n",
        "    client,\n",
        "    model=\"gpt-5-mini\",\n",
        "    developer_message=\"You are a helpful teaching assistant. Reply in Korean with actionable suggestions.\",\n",
        "    reasoning_effort=\"low\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "reply, raw_response = chatbot.send(\"Responses API ì‹¤ìŠµì„ ë³µìŠµí•˜ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì„ ì•Œë ¤ ì¤˜.\")\n",
        "print(\"ëª¨ë¸ ì‘ë‹µ:\\n\", reply)\n",
        "\n",
        "print(\"\\ní˜„ì¬ íˆìŠ¤í† ë¦¬:\\n\", chatbot.pretty_history())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_response.usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) ìœ„ì ¯ ê¸°ë°˜ ì±—ë´‡ UI (ì •ë‹µ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "chat_ui_session = ChatSession(\n",
        "    client,\n",
        "    model=\"gpt-5-mini\",\n",
        "    developer_message=\"You are a supportive study buddy. Reply in Korean with friendly tips.\",\n",
        "    reasoning_effort=\"medium\",\n",
        ")\n",
        "\n",
        "log_output = widgets.Output(layout=widgets.Layout(border=\"1px solid #ccc\", padding=\"8px\"))\n",
        "input_box = widgets.Text(\n",
        "    placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enter ë˜ëŠ” 'ì „ì†¡'ì„ í´ë¦­í•˜ì„¸ìš”.\",\n",
        "    description=\"ì§ˆë¬¸\",\n",
        "    layout=widgets.Layout(width=\"100%\"),\n",
        ")\n",
        "send_button = widgets.Button(description=\"ì „ì†¡\", button_style=\"primary\")\n",
        "reset_button = widgets.Button(description=\"ì´ˆê¸°í™”\")\n",
        "status_label = widgets.HTML(value=\"\")\n",
        "\n",
        "\n",
        "def append_message(role: str, text: str) -> None:\n",
        "    with log_output:\n",
        "        display(Markdown(f\"**{role}**: {text}\"))\n",
        "\n",
        "\n",
        "def handle_send(_=None) -> None:\n",
        "    text = input_box.value.strip()\n",
        "    if not text:\n",
        "        status_label.value = \"<span style='color:#d9534f;'>ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.</span>\"\n",
        "        return\n",
        "\n",
        "    status_label.value = \"\"\n",
        "    append_message(\"ì‚¬ìš©ì\", text)\n",
        "    input_box.value = \"\"\n",
        "    send_button.disabled = True\n",
        "    try:\n",
        "        answer, _ = chat_ui_session.send(text)\n",
        "        append_message(\"ì–´ì‹œìŠ¤í„´íŠ¸\", answer)\n",
        "    except Exception as exc:  # pragma: no cover\n",
        "        append_message(\"ì˜¤ë¥˜\", f\"{type(exc).__name__}: {exc}\")\n",
        "    finally:\n",
        "        send_button.disabled = False\n",
        "\n",
        "\n",
        "def handle_reset(_=None) -> None:\n",
        "    chat_ui_session.reset()\n",
        "    log_output.clear_output()\n",
        "    status_label.value = \"<span style='color:#5cb85c;'>ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.</span>\"\n",
        "\n",
        "\n",
        "send_button.on_click(handle_send)\n",
        "reset_button.on_click(handle_reset)\n",
        "input_box.on_submit(handle_send)\n",
        "\n",
        "controls = widgets.HBox([send_button, reset_button, status_label])\n",
        "ui = widgets.VBox([input_box, controls, log_output])\n",
        "\n",
        "display(ui)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
