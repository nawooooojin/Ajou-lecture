{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eb42d6",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ§ª GPT-5-mini â€” Responses API ì‹¤ìŠµ (Colab)\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **GPT-5-mini**ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤.  \n",
    "ì¤‘ì : **`instructions` + `input` êµ¬ì¡°**, **`reasoning.effort`**, **`text.verbosity`**, **`max_output_tokens`**.\n",
    "\n",
    "> âš ï¸ GPT-5 ê³„ì—´ì€ `temperature`, `top_p`, `logprobs` **ë¯¸ì§€ì›**ì…ë‹ˆë‹¤. (ìš”ì²­ ì‹œ ì—ëŸ¬)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ca28e",
   "metadata": {},
   "source": [
    "\n",
    "## 1) í™˜ê²½ ì…‹ì—…\n",
    "ìµœì‹  OpenAI Python SDK ì„¤ì¹˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -qU install openai>=1.55.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b94862",
   "metadata": {},
   "source": [
    "\n",
    "## 2) API í‚¤ ì„¤ì •\n",
    "Colab ìƒë‹¨ **Settings â†’ Variables**ì— `OPENAI_API_KEY`ë¥¼ ì €ì¥í•´ë‘ì—ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.  \n",
    "ì—†ìœ¼ë©´ ì•„ë˜ ì…€ì—ì„œ ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = None\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "print(\"âœ… API key set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeae516",
   "metadata": {},
   "source": [
    "\n",
    "## 3) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” & ëª¨ë¸ ì„ íƒ\n",
    "- ê¸°ë³¸ ëª¨ë¸: **`gpt-5-mini`**\n",
    "- (ì˜µì…˜) ì ‘ê·¼ ë¶ˆê°€ ì‹œ **`gpt-4o-mini`**ë¡œ í´ë°±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b906c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "PRIMARY_MODEL = \"gpt-5-mini\"\n",
    "FALLBACK_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def pick_model():\n",
    "    try:\n",
    "        # Minimal probe call\n",
    "        _ = client.responses.create(\n",
    "            model=PRIMARY_MODEL,\n",
    "            reasoning={\"effort\": \"minimal\"},\n",
    "            text={\"verbosity\": \"low\"},\n",
    "            input=\"ping\",\n",
    "            max_output_tokens=5,\n",
    "        )\n",
    "        return PRIMARY_MODEL\n",
    "    except Exception as e:\n",
    "        print(\"[warn] gpt-5-mini not available â†’ falling back to gpt-4o-mini\")\n",
    "        return FALLBACK_MODEL\n",
    "\n",
    "MODEL = pick_model()\n",
    "print(\"Using model:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e973e8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Quickstart â€” `instructions` + `input`\n",
    "Responses APIì˜ ê¶Œì¥ í˜•ì‹ì€ **`instructions`**(ê°œëµì  ì—­í• /ìŠ¤íƒ€ì¼)ê³¼ **`input`**(ì‚¬ìš©ì ì§ˆë¬¸) ë¶„ë¦¬ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa01eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"medium\"},\n",
    "    instructions=\"You are a friendly instructor who explains AI concepts simply and precisely.\",\n",
    "    input=\"Explain what a Large Language Model is in 2-3 sentences.\",\n",
    "    max_output_tokens=150,\n",
    ")\n",
    "print(response.output_text)\n",
    "try:\n",
    "    print(\"\\n[usage]\", response.usage)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715df58",
   "metadata": {},
   "source": [
    "\n",
    "### ğŸ´â€â˜ ï¸ ì˜ˆì‹œ: ìŠ¤íƒ€ì¼ ì§€ì‹œ (pirate tone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    instructions=\"Talk like a pirate.\",\n",
    "    input=\"Are semicolons optional in JavaScript? Answer in one short sentence.\",\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=60,\n",
    ")\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd05bdb",
   "metadata": {},
   "source": [
    "\n",
    "## 5) í—¬í¼ í•¨ìˆ˜ â€” `ask_mini()`\n",
    "ì‹¤í—˜ ë°˜ë³µì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ ë˜í¼ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_mini(\n",
    "    user_input: str,\n",
    "    instructions: str = \"You are a helpful assistant.\",\n",
    "    reasoning_effort: str = \"medium\",\n",
    "    verbosity: str = \"medium\",\n",
    "    max_tokens: int = 300,\n",
    "    model: str = MODEL,\n",
    "):\n",
    "    r = client.responses.create(\n",
    "        model=model,\n",
    "        reasoning={\"effort\": reasoning_effort},\n",
    "        text={\"verbosity\": verbosity},\n",
    "        instructions=instructions,\n",
    "        input=user_input,\n",
    "        max_output_tokens=max_tokens,\n",
    "    )\n",
    "    return r\n",
    "\n",
    "demo = ask_mini(\"List three practical tips for writing better prompts.\", verbosity=\"low\", max_tokens=120)\n",
    "print(demo.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8de84b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) ì‹¤ìŠµ 1 â€” `reasoning.effort` ë¹„êµ\n",
    "ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´ `minimal / low / medium / high` ì°¨ì´ë¥¼ ê´€ì°°í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Explain overfitting to a beginner in <= 4 sentences.\"\n",
    "for effort in [\"minimal\", \"low\", \"medium\", \"high\"]:\n",
    "    print(f\"\\n=== reasoning.effort = {effort} ===\")\n",
    "    r = ask_mini(question, reasoning_effort=effort, verbosity=\"medium\", max_tokens=220)\n",
    "    print(r.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348b33c",
   "metadata": {},
   "source": [
    "\n",
    "## 7) ì‹¤ìŠµ 2 â€” `text.verbosity` ë¹„êµ\n",
    "`low / medium / high`ì— ë”°ë¼ ì‘ë‹µ ê¸¸ì´ì™€ ì„¤ëª… ì •ë„ê°€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ë¹„êµí•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9055f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"What is a binary search tree? Include a tiny Python snippet.\"\n",
    "for v in [\"low\", \"medium\", \"high\"]:\n",
    "    print(f\"\\n=== text.verbosity = {v} ===\")\n",
    "    r = ask_mini(question, reasoning_effort=\"low\", verbosity=v, max_tokens=400)\n",
    "    print(r.output_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ba1e6",
   "metadata": {},
   "source": [
    "\n",
    "## 8) ì‹¤ìŠµ 3 â€” `max_output_tokens` ì˜í–¥\n",
    "ì¶œë ¥ ê¸¸ì´ë¥¼ 60 / 150 / 400ìœ¼ë¡œ ë°”ê¿” ë³´ê³ , ì–´ë””ì„œ ì˜ë¦¬ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d86805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Give a step-by-step guide to implement a simple REST API server in Python using FastAPI.\"\n",
    "for m in [60, 150, 400]:\n",
    "    print(f\"\\n=== max_output_tokens = {m} ===\")\n",
    "    r = ask_mini(question, reasoning_effort=\"medium\", verbosity=\"high\", max_tokens=m)\n",
    "    print(r.output_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faf736",
   "metadata": {},
   "source": [
    "\n",
    "## 9) êµ¬ì¡°í™”(JSON) ì‘ë‹µ\n",
    "`response_format={\"type\":\"json_object\"}`ë¡œ íŒŒì‹± ê°€ëŠ¥í•œ ì¶œë ¥ ë°›ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47859de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "prompt = \"Summarize in <=2 sentences and extract 3 keywords: GPT-5-mini balances speed, cost, and capability.\"\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    instructions=\"Return a valid JSON object only. Keys: summary, keywords (list).\",\n",
    "    input=prompt,\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=150,\n",
    ")\n",
    "print(\"Raw:\", resp.output_text)\n",
    "try:\n",
    "    print(\"Parsed:\", json.loads(resp.output_text))\n",
    "except Exception as e:\n",
    "    print(\"JSON parse error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e267e",
   "metadata": {},
   "source": [
    "\n",
    "## 10) (ì„ íƒ) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "í† í° ë‹¨ìœ„ë¡œ ì ì§„ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d366ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def response_stream(**kwargs):\n",
    "    s = client.responses.stream(**kwargs)\n",
    "    try:\n",
    "        yield s\n",
    "    finally:\n",
    "        s.close()\n",
    "\n",
    "with response_stream(\n",
    "    model=MODEL,\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    instructions=\"Be concise.\",\n",
    "    input=\"Write a 5-line poem about on-device acceleration.\",\n",
    "    max_output_tokens=120,\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == \"response.completed\":\n",
    "            print(\"\\n\\n[completed]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38c66f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… / ìœ ì˜ì‚¬í•­\n",
    "- **ë¯¸ì§€ì› íŒŒë¼ë¯¸í„°**: `temperature`, `top_p`, `logprobs` â†’ **ì‚¬ìš© ê¸ˆì§€**  \n",
    "- **ì§€ì—° ë‹¨ì¶•**: `reasoning.effort` ë‚®ì¶”ê¸°, `text.verbosity=\"low\"`, `max_output_tokens` ì¶•ì†Œ  \n",
    "- **ê³¼ê¸ˆ ê´€ë¦¬**: ê¸´ ì‘ë‹µ/ë°˜ë³µ í˜¸ì¶œì„ í”¼í•˜ê³ , ì¶œë ¥ ê¸¸ì´ë¥¼ ì œí•œí•˜ì„¸ìš”.\n",
    "- **ì ‘ê·¼ ê¶Œí•œ ë¬¸ì œ**: ë³¸ ë…¸íŠ¸ë¶ì€ `gpt-5-mini` ì‹¤íŒ¨ ì‹œ `gpt-4o-mini`ë¡œ í´ë°±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20682280",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "_Last updated: 2025-11-06 14:19:35_  \n",
    "Â© Ajou Univ. **ëª¨ë°”ì¼ ì»´í“¨íŒ… íŠ¹ë¡ ** â€” GPT-5-mini Responses Lab\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
