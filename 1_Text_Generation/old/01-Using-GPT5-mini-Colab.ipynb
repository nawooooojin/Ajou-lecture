{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f041d15",
   "metadata": {},
   "source": [
    "\n",
    "# âš¡ Using **GPT-5-mini** â€” Colab ì‹¤ìŠµ ë…¸íŠ¸ë¶\n",
    "ì´ ë…¸íŠ¸ë¶ì€ OpenAI **Responses API**ì—ì„œ **GPT-5-mini**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤.  \n",
    "í•µì‹¬: **reasoning.effort**, **text.verbosity**, **max_output_tokens** (GPT-5 ê³„ì—´: `temperature/top_p/logprobs` ë¯¸ì§€ì›).\n",
    "\n",
    "> ì ‘ê·¼ ê¶Œí•œ/ë¦¬ì „ ì´ìŠˆê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë¶ˆê°€ ì‹œ ìë™ìœ¼ë¡œ `gpt-4o-mini`ë¡œ **í´ë°±**í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5d3e1",
   "metadata": {},
   "source": [
    "\n",
    "## 1) í™˜ê²½ ì…‹ì—…\n",
    "- ìµœì‹  OpenAI Python SDK ì„¤ì¹˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -qU install openai>=1.55.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7f2e7",
   "metadata": {},
   "source": [
    "\n",
    "## 2) API í‚¤ ì„¤ì •\n",
    "Colab **Settings â†’ Variables**ì— `OPENAI_API_KEY` ì €ì¥ ê¶Œì¥. ì—†ìœ¼ë©´ ì•„ë˜ ì…€ì—ì„œ ì…ë ¥.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = None\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "print(\"âœ… API key set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11181233",
   "metadata": {},
   "source": [
    "\n",
    "## 3) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” & ëª¨ë¸ ì„ íƒ (í´ë°± í¬í•¨)\n",
    "- ê¸°ë³¸ íƒ€ê¹ƒ: `gpt-5-mini`  \n",
    "- ì‹¤íŒ¨ ì‹œ: `gpt-4o-mini`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf57b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "PRIMARY_MODEL = \"gpt-5-mini\"\n",
    "FALLBACK_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def pick_model():\n",
    "    try:\n",
    "        _ = client.responses.create(\n",
    "            model=PRIMARY_MODEL,\n",
    "            input=\"ping\",\n",
    "            reasoning={\"effort\": \"minimal\"},\n",
    "            max_output_tokens=5,\n",
    "            text={\"verbosity\": \"low\"},\n",
    "        )\n",
    "        return PRIMARY_MODEL\n",
    "    except Exception:\n",
    "        print(\"[warn] gpt-5-mini not available â†’ falling back to gpt-4o-mini\")\n",
    "        return FALLBACK_MODEL\n",
    "\n",
    "MODEL = pick_model()\n",
    "print(\"Using model:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462612c8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Quickstart â€” ë¹ ë¥¸ ì‘ë‹µ(ì €ì§€ì—°)\n",
    "- `reasoning.effort`: `\"low\"` ë˜ëŠ” `\"minimal\"`  \n",
    "- `text.verbosity`: `\"low\"`  \n",
    "- `max_output_tokens`: ì‘ë‹µ ê¸¸ì´ ì œì–´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"Write a haiku about clean, elegant Python code.\",\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=80,\n",
    ")\n",
    "print(resp.output_text)\n",
    "try:\n",
    "    print(\"\\n[usage]\", resp.usage)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81684d3c",
   "metadata": {},
   "source": [
    "\n",
    "## 5) ê³ ë‚œë„ íƒœìŠ¤í¬ â€” ë†’ì€ ì¶”ë¡  ë…¸ë ¥\n",
    "ë³µì¡í•œ ë²„ê·¸ ë¶„ì„/ê³„íš ìˆ˜ë¦½ì—ëŠ” `reasoning.effort=\"high\"`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Find the bug and fix it. Code:\\n\\nfunction add(a, b) { if (!a) return; return a + b; }\"\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    "    reasoning={\"effort\": \"high\"},\n",
    "    text={\"verbosity\": \"medium\"},\n",
    "    max_output_tokens=400,\n",
    ")\n",
    "print(resp.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a10b7a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Minimal reasoning â€” ê·¹ì €ì§€ì—°\n",
    "ì¶”ë¡  í† í°ì„ ìµœì†Œí™”í•´ ì¦‰ë‹µì— ê°€ê¹ê²Œ ì‘ë‹µ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a8c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"How many letters r are in 'blueberry'? Return only the integer.\",\n",
    "    reasoning={\"effort\": \"minimal\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=10,\n",
    ")\n",
    "print(resp.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3fbd71",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Verbosity ë¹„êµ ì‹¤í—˜\n",
    "ê°™ì€ ì§ˆë¬¸ìœ¼ë¡œ `low/medium/high` ë¹„êµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d764822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Explain what a binary search tree is, and show a short Python example.\"\n",
    "for v in [\"low\", \"medium\", \"high\"]:\n",
    "    print(f\"\\n=== verbosity={v} ===\")\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=question,\n",
    "        reasoning={\"effort\": \"low\"},\n",
    "        text={\"verbosity\": v},\n",
    "        max_output_tokens=400,\n",
    "    )\n",
    "    print(resp.output_text[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a39878",
   "metadata": {},
   "source": [
    "\n",
    "## 8) í—¬í¼ í•¨ìˆ˜ â€” `ask5mini()`\n",
    "ë°˜ë³µ ì‹¤í—˜ì„ ê°„í¸í™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask5mini(prompt: str,\n",
    "             reasoning_effort: str = \"medium\",\n",
    "             verbosity: str = \"medium\",\n",
    "             max_tokens: int = 400,\n",
    "             system_prompt: str | None = None):\n",
    "    payload = []\n",
    "    if system_prompt:\n",
    "        payload.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    payload.append({\"role\": \"user\", \"content\": prompt})\n",
    "    r = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=payload,\n",
    "        reasoning={\"effort\": reasoning_effort},\n",
    "        text={\"verbosity\": verbosity},\n",
    "        max_output_tokens=max_tokens,\n",
    "    )\n",
    "    return r\n",
    "\n",
    "demo = ask5mini(\"List 3 benefits of Responses API succinctly.\", \"low\", \"low\", 120)\n",
    "print(demo.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541b14d",
   "metadata": {},
   "source": [
    "\n",
    "## 9) êµ¬ì¡°í™”(JSON) ì‘ë‹µ\n",
    "`response_format={\"type\":\"json_object\"}`ë¡œ íŒŒì‹± ê°€ëŠ¥í•œ ê²°ê³¼ ë°›ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "prompt = \"Summarize this in <=2 sentences and extract 3 keywords: GPT-5-mini balances speed, cost, and capability.\"\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=120,\n",
    ")\n",
    "print(\"Raw:\", resp.output_text)\n",
    "try:\n",
    "    print(\"Parsed:\", json.loads(resp.output_text))\n",
    "except Exception as e:\n",
    "    print(\"JSON parse error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1c388",
   "metadata": {},
   "source": [
    "\n",
    "## 10) (ì„ íƒ) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "í† í° ë‹¨ìœ„ë¡œ ì ì§„ì  ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def response_stream(**kwargs):\n",
    "    s = client.responses.stream(**kwargs)\n",
    "    try:\n",
    "        yield s\n",
    "    finally:\n",
    "        s.close()\n",
    "\n",
    "with response_stream(\n",
    "    model=MODEL,\n",
    "    input=\"Write a 5-line poem about on-device acceleration.\",\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    text={\"verbosity\": \"low\"},\n",
    "    max_output_tokens=120,\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\")\n",
    "        elif event.type == \"response.completed\":\n",
    "            print(\"\\n\\n[completed]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede7b4f",
   "metadata": {},
   "source": [
    "\n",
    "## 11) (ì°¸ê³ ) Custom tools / Allowed tools â€” ìš”ì²­ ìƒ˜í”Œ\n",
    "ìˆ˜ì—…ì—ì„œëŠ” ê°œë…ê³¼ ë³´ì•ˆ(ì„œë²„ ì¸¡ ê²€ì¦)ì„ ê°•ì¡°í•˜ê³ , ì‹¤ì œ ì‹¤í–‰ì€ ì„œë²„ ìƒŒë“œë°•ìŠ¤ì—ì„œ ë‹¤ë£¨ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b00562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_payload_custom_tool = {\n",
    "    \"model\": \"gpt-5-mini\",\n",
    "    \"input\": \"Use the code_exec tool to calculate area of a circle with r=3.\",\n",
    "    \"tools\": [\n",
    "        {\"type\": \"custom\", \"name\": \"code_exec\", \"description\": \"Executes arbitrary python code\"}\n",
    "    ]\n",
    "}\n",
    "example_payload_allowed_tools = {\n",
    "    \"model\": \"gpt-5-mini\",\n",
    "    \"input\": \"Search docs for 'Responses API' and summarize.\",\n",
    "    \"tools\": [\n",
    "        {\"type\": \"function\", \"name\": \"search_docs\", \"description\": \"Searches internal docs by keyword\"},\n",
    "        {\"type\": \"function\", \"name\": \"get_weather\", \"description\": \"Gets current weather\"}\n",
    "    ],\n",
    "    \"tool_choice\": {\n",
    "        \"type\": \"allowed_tools\",\n",
    "        \"mode\": \"auto\",\n",
    "        \"tools\": [\n",
    "            {\"type\": \"function\", \"name\": \"search_docs\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "print(\"Custom tool sample:\", example_payload_custom_tool)\n",
    "print(\"\\nAllowed tools sample:\", example_payload_allowed_tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe471b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## ğŸ§ª ì‹¤ìŠµ ê³¼ì œ\n",
    "1) **ì§€ì—°/í’ˆì§ˆ íŠ¸ë ˆì´ë“œì˜¤í”„**: ë™ì¼ ì§ˆë¬¸ì— ëŒ€í•´  \n",
    "   - `reasoning.effort`: minimal/low/medium/high  \n",
    "   - `text.verbosity`: low/medium/high  \n",
    "   3ê°œ ì´ìƒ ì¡°í•© ì‹¤í—˜ í›„, **ì†ë„/ê¸¸ì´/í’ˆì§ˆ ì°¨ì´**ë¥¼ 5ì¤„ ìš”ì•½.\n",
    "\n",
    "2) **ì½”ë”© ë””ë²„ê¹…**: 10~20ì¤„ ì˜¤ë¥˜ ì½”ë“œë¡œ `reasoning.effort=\"high\"` í…ŒìŠ¤íŠ¸.  \n",
    "   ê²°ê³¼ ì½”ë“œë¥¼ ë³„ë„ í™˜ê²½ì—ì„œ ì‹¤í–‰í•´ ë™ì‘ ì—¬ë¶€ í™•ì¸(ë³´ê³ ë§Œ).\n",
    "\n",
    "3) **JSON ìŠ¤í‚¤ë§ˆ ì„¤ê³„**: ìš”ì•½/í‚¤ì›Œë“œ/ë‚œì´ë„(1~5)/ì¶”ê°€ìë£Œ ë§í¬ í¬í•¨ JSONìœ¼ë¡œ ë‘ ë¬¸ë‹¨ ë¹„êµ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779f76a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "_Last updated: 2025-11-06 14:05:57_  \n",
    "Â© Ajou Univ. **ëª¨ë°”ì¼ ì»´í“¨íŒ… íŠ¹ë¡ ** â€” Using GPT-5-mini Lab\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
