{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# âœ… Week2: STT ì‹¤ìŠµ ì†”ë£¨ì…˜\n",
        "\n",
        "> **ì£¼ì˜:** Colab ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ë©´ `OPENAI_API_KEY`ë¥¼ ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì§„í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì¤€ë¹„ ë° ê¸°ë³¸ ì „ì‚¬ í•¨ìˆ˜\n",
        "2. ê³ ê¸‰ ì˜µì…˜: ì‘ë‹µ í¬ë§·/í”„ë¡¬í”„íŠ¸\n",
        "3. ë°œí™”ì êµ¬ë¶„(Diarization)\n",
        "4. ë²ˆì—­(Translations)\n",
        "5. íƒ€ì„ìŠ¤íƒ¬í”„ ë° ê¸´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì•„ì´ë””ì–´\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ì‹¤ìŠµê³¼ ë™ì¼í•œ ìˆœì„œë¡œ ì •ë‹µ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œëŠ” ìƒí™©ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"âœ… í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) ê¸°ë³¸ ì „ì‚¬ í•¨ìˆ˜\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_path, *, model=\"gpt-4o-transcribe\", response_format=\"text\"):\n",
        "    path = Path(audio_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}\")\n",
        "\n",
        "    with path.open(\"rb\") as audio_file:\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            model=model,\n",
        "            file=audio_file,\n",
        "            response_format=response_format,\n",
        "        )\n",
        "\n",
        "    return transcription.text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sample_text = transcribe_audio(\"data/sample_lecture.mp3\")\n",
        "# print(sample_text[:200])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) í”„ë¡¬í”„íŠ¸ ë° ì‘ë‹µ í¬ë§· ì˜µì…˜\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_with_prompt(audio_path, *, prompt=None, response_format=\"json\"):\n",
        "    path = Path(audio_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "\n",
        "    kwargs = {\n",
        "        \"model\": \"gpt-4o-transcribe\",\n",
        "        \"response_format\": response_format,\n",
        "    }\n",
        "    if prompt:\n",
        "        kwargs[\"prompt\"] = prompt\n",
        "\n",
        "    with path.open(\"rb\") as audio_file:\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            file=audio_file,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    if response_format == \"json\":\n",
        "        return transcription.text\n",
        "    return transcription.text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Diarization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diarize_audio(audio_path, *, chunking_strategy=\"auto\"):\n",
        "    path = Path(audio_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "\n",
        "    with path.open(\"rb\") as audio_file:\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "            model=\"gpt-4o-transcribe-diarize\",\n",
        "            file=audio_file,\n",
        "            response_format=\"diarized_json\",\n",
        "            chunking_strategy=chunking_strategy,\n",
        "        )\n",
        "\n",
        "    segments = []\n",
        "    for segment in transcript.segments:\n",
        "        segments.append(\n",
        "            {\n",
        "                \"speaker\": segment.speaker,\n",
        "                \"text\": segment.text,\n",
        "                \"start\": segment.start,\n",
        "                \"end\": segment.end,\n",
        "            }\n",
        "        )\n",
        "    return segments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) ë²ˆì—­\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_audio(audio_path, *, model=\"whisper-1\"):\n",
        "    path = Path(audio_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "\n",
        "    with path.open(\"rb\") as audio_file:\n",
        "        translation = client.audio.translations.create(\n",
        "            model=model,\n",
        "            file=audio_file,\n",
        "        )\n",
        "\n",
        "    return translation.text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) íƒ€ì„ìŠ¤íƒ¬í”„ ì˜µì…˜\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_with_timestamps(audio_path):\n",
        "    path = Path(audio_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "\n",
        "    with path.open(\"rb\") as audio_file:\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file,\n",
        "            response_format=\"verbose_json\",\n",
        "            timestamp_granularities=[\"word\"],\n",
        "        )\n",
        "\n",
        "    return transcription.words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì€ PyDub ë“±ìœ¼ë¡œ ë¶„í• í•˜ê³ , ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ë¥¼ promptë¡œ ì „ë‹¬í•˜ë©´ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ğŸ’¡ í”„ë¡œì íŠ¸ ì‘ìš©: íšŒì˜ ìš”ì•½ ìë™í™”, ë‹¤êµ­ì–´ ìë§‰ ìƒì„±, ì‹¤ì‹œê°„ ìº¡ì…˜ ë“±ìœ¼ë¡œ í™•ì¥í•´ ë³´ì„¸ìš”.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
