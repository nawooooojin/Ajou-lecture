{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ–¼ï¸ Week2: GPT-5 ì´ë¯¸ì§€ ì‹¤ìŠµ (ì •ë‹µ)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **ì£¼ì˜:** Colab ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ë©´ `OPENAI_API_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì§„í–‰ ìˆœì„œ\n",
        "1. í™˜ê²½ ì¤€ë¹„ ë° ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±\n",
        "2. ì´ë¯¸ì§€ ì €ì¥ Â· í‘œì‹œ ë° ì¶œë ¥ ì˜µì…˜ ì‹¤ìŠµ\n",
        "3. ë©€í‹°í„´ ì´ë¯¸ì§€ ê°œì„ (Responses API)\n",
        "4. ì´ë¯¸ì§€ ë¶„ì„(ë¹„ì „) ê¸°ë³¸ ì‹¤ìŠµ\n",
        "5. ì„ íƒ ê³¼ì œ & í™•ì¥ ì•„ì´ë””ì–´\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) í™˜ê²½ ì¤€ë¹„ ë° ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    OPENAI_API_KEY = getpass(\"Enter your OPENAI_API_KEY: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from IPython.display import display, Image as DisplayImage\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"âœ… í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT Image ì‹¤ìŠµ ì •ë‹µ ì½”ë“œ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_image(prompt: str, *, size: str = \"1024x1024\", quality: str = \"medium\") -> bytes:\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        input=prompt,\n",
        "        tools=[\n",
        "            {\n",
        "                \"type\": \"image_generation\",\n",
        "                \"size\": size,\n",
        "                \"quality\": quality,\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    image_data = [\n",
        "        output.result\n",
        "        for output in response.output\n",
        "        if output.type == \"image_generation_call\"\n",
        "    ]\n",
        "\n",
        "    if not image_data:\n",
        "        raise RuntimeError(\"ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    return base64.b64decode(image_data[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì˜ˆì‹œ ì‹¤í–‰\n",
        "prompt = \"A cozy reading nook with floor-to-ceiling bookshelves and warm lighting\"\n",
        "img_bytes = generate_image(prompt, size=\"1024x1024\", quality=\"high\")\n",
        "with open(\"reading_nook.png\", \"wb\") as f:\n",
        "    f.write(img_bytes)\n",
        "print(\"âœ… ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ ì™„ë£Œ -> reading_nook.png\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_image(image_path: str) -> None:\n",
        "    display(DisplayImage(filename=image_path))\n",
        "\n",
        "show_image(\"reading_nook.png\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def refine_image(prompt: str, follow_up: str) -> tuple[str, bytes]:\n",
        "    initial = client.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        input=prompt,\n",
        "        tools=[{\"type\": \"image_generation\"}],\n",
        "    )\n",
        "\n",
        "    first_calls = [\n",
        "        output\n",
        "        for output in initial.output\n",
        "        if output.type == \"image_generation_call\"\n",
        "    ]\n",
        "    if not first_calls:\n",
        "        raise RuntimeError(\"ì´ˆê¸° ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    followup = client.responses.create(\n",
        "        model=\"gpt-5\",\n",
        "        previous_response_id=initial.id,\n",
        "        input=follow_up,\n",
        "        tools=[{\"type\": \"image_generation\"}],\n",
        "    )\n",
        "\n",
        "    follow_calls = [\n",
        "        output\n",
        "        for output in followup.output\n",
        "        if output.type == \"image_generation_call\"\n",
        "    ]\n",
        "    if not follow_calls:\n",
        "        raise RuntimeError(\"í›„ì† ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    return followup.id, base64.b64decode(follow_calls[0].result)\n",
        "\n",
        "\n",
        "# ì˜ˆì‹œ ì‹¤í–‰ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)\n",
        "# base_prompt = \"Generate a stylized poster of a futuristic city skyline at sunset\"\n",
        "# follow_up_prompt = \"Increase the level of realism and add flying cars\"\n",
        "# refined_id, refined_bytes = refine_image(base_prompt, follow_up_prompt)\n",
        "# with open(\"city_refined.png\", \"wb\") as f:\n",
        "#     f.write(refined_bytes)\n",
        "# show_image(\"city_refined.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def describe_image(image_url: str, question: str, *, detail: str = \"auto\") -> str:\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"input_text\", \"text\": question},\n",
        "                    {\n",
        "                        \"type\": \"input_image\",\n",
        "                        \"image_url\": image_url,\n",
        "                        \"detail\": detail,\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "\n",
        "# ì˜ˆì‹œ ì‹¤í–‰ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)\n",
        "# sample_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/1024px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "# print(describe_image(sample_url, \"ì´ë¯¸ì§€ ì† ì£¼ìš” ëŒ€ìƒê³¼ ë¶„ìœ„ê¸°ë¥¼ ì„¤ëª…í•´ ì¤˜\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_file(image_path: str) -> dict:\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "    return {\n",
        "        \"type\": \"input_image\",\n",
        "        \"image_base64\": encoded,\n",
        "    }\n",
        "\n",
        "\n",
        "# ì˜ˆì‹œ ì‹¤í–‰ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)\n",
        "# local_image_payload = create_file(\"reading_nook.png\")\n",
        "# vision_response = client.responses.create(\n",
        "#     model=\"gpt-4.1-mini\",\n",
        "#     input=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\"type\": \"input_text\", \"text\": \"ì´ ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì¤˜\"},\n",
        "#                 local_image_payload,\n",
        "#             ],\n",
        "#         }\n",
        "#     ],\n",
        "# )\n",
        "# print(vision_response.output_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
